{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T03:51:38.029819Z",
     "start_time": "2019-07-14T03:51:38.026826Z"
    }
   },
   "source": [
    "Vou montar aqui um pipeline mais robusto, mais próximo do produtivo, focando em lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definições iniciais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T04:59:53.035409Z",
     "start_time": "2019-07-14T04:59:53.020395Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, RandomizedSearchCV, train_test_split, StratifiedKFold,cross_val_score\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Hyperopt\n",
    "from hyperopt import fmin, hp, tpe, rand, Trials, space_eval, STATUS_OK, anneal\n",
    "from hyperopt.pyll import scope as ho_scope\n",
    "from hyperopt.pyll.stochastic import sample as ho_sample\n",
    "from functools import partial\n",
    "\n",
    "# Category encoders\n",
    "from category_encoders.hashing import HashingEncoder\n",
    "from category_encoders.sum_coding import SumEncoder\n",
    "from category_encoders.woe import WOEEncoder\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from category_encoders.one_hot import OneHotEncoder\n",
    "from category_encoders.binary import BinaryEncoder\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Files\n",
    "# Files\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "from joblib import Memory\n",
    "import joblib\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurando random pra deixar reprodutível"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T03:52:13.192793Z",
     "start_time": "2019-07-14T03:52:13.190791Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "random_global = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções úteis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função pra submeter os resultados e salvar os arquivos necessários pra replicar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T03:52:14.666132Z",
     "start_time": "2019-07-14T03:52:14.654131Z"
    }
   },
   "outputs": [],
   "source": [
    "class SaveModel(object):\n",
    "    def __init__(self, folder_to_save, data_train=None, data_val=None, data_test=None, model=None, str_readme=None, submission_file='submission.csv'):\n",
    "        self.folder_to_save = folder_to_save\n",
    "        self.data_train = data_train\n",
    "        self.data_val = data_val\n",
    "        self.data_test = data_test\n",
    "        self.model = model\n",
    "        self.str_readme = str_readme\n",
    "        self.submission_file = submission_file\n",
    "    \n",
    "    def save_model(self):\n",
    "#     Create folder if not exists:\n",
    "        try:\n",
    "            os.makedirs(self.folder_to_save)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    #     Salva os dados usados no treino\n",
    "        if self.data_train is not None:\n",
    "            joblib.dump(self.data_train, self.folder_to_save+'/train_data')\n",
    "\n",
    "\n",
    "    #     Salva dados usados na validação\n",
    "        if self.data_val is not None:\n",
    "            joblib.dump(self.data_test, self.folder_to_save+'/validation_data')\n",
    "\n",
    "    #     Salva dados usados no teste\n",
    "        if self.data_test is not None:\n",
    "            joblib.dump(self.data_test, self.folder_to_save+'/test_data')\n",
    "\n",
    "    #     Salva modelo \n",
    "        if self.model is not None:\n",
    "            joblib.dump(self.model, self.folder_to_save+'/model')   \n",
    "\n",
    "    #     Arquivo README (é o que vai escrito pro commit)\n",
    "        with open(self.folder_to_save+'/README.txt', \"w\") as text_file:\n",
    "            text_file.write(self.str_readme)\n",
    "            \n",
    "#         Salva os predictions\n",
    "        \n",
    "\n",
    "    def commit_kaggle(self):\n",
    "        predictions = self.model.predict(self.data_test)\n",
    "        submission = pd.DataFrame({'PassengerId':self.data_test['passengerid'],'Survived':predictions})\n",
    "        submission.to_csv(self.folder_to_save+'/'+self.submission_file,index=False)\n",
    "#         print(f\"kaggle competitions submit -c titanic -f submission.csv -m \\\"{self.str_readme}\\\"\")\n",
    "#         !! f\"kaggle competitions submit -c titanic -f {self.folder_to_save+'/'+self.submission_file} -m \\\"{self.str_readme}\\\"\"\n",
    "        if os.system(f\"kaggle competitions submit -c titanic -f {self.folder_to_save+'/'+self.submission_file} -m \\\"{self.str_readme}\\\"\") != 0:\n",
    "            print('Erro submetendo o arquivo no kaggle!')\n",
    "            \n",
    "        print(f\"kaggle competitions submit -c titanic -f {self.folder_to_save+'/'+self.submission_file} -m \\\"{self.str_readme}\\\"\")\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T05:02:22.544747Z",
     "start_time": "2019-07-14T05:02:22.531734Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from functools import reduce\n",
    "\n",
    "class TransformToDF(BaseEstimator, TransformerMixin):\n",
    "    '''Wrapper para usar transformers do sklearn mas retorna um dataframe Pandas. Projetei para usar com transformers que não\n",
    "    mudam o número de colunas na saída.'''\n",
    "    \n",
    "    def __init__(self, sklearn_transformer, return_df=True):\n",
    "        self.sklearn_transformer = sklearn_transformer\n",
    "        self.return_df = return_df\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            self.col_names = X.columns.values.tolist()\n",
    "            \n",
    "        self.sklearn_transformer.fit(X, y=None)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "    # assumes X is a DataFrame\n",
    "        if self.return_df:\n",
    "            return pd.DataFrame(self.sklearn_transformer.transform(X[self.col_names]), index=X.index, columns=self.col_names)\n",
    "        else:\n",
    "            return self.sklearn_transformer.transform(X)\n",
    "        \n",
    "class DFFeatureUnion(BaseEstimator,TransformerMixin):\n",
    "    # FeatureUnion but for pandas DataFrames\n",
    "\n",
    "    def __init__(self, transformer_list):\n",
    "        self.transformer_list = transformer_list\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for (name, t) in self.transformer_list:\n",
    "            t.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xts = [t.transform(X) for _, t in self.transformer_list]\n",
    "        Xunion = reduce(lambda X1, X2: pd.merge(X1, X2, left_index=True, right_index=True), Xts)\n",
    "        return Xunion\n",
    "    \n",
    "class ColumnExtractor(BaseEstimator,TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols, return_df=True):\n",
    "        self.cols = cols\n",
    "        self.return_df = return_df\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # stateless transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        if self.return_df:\n",
    "            return X[self.cols]\n",
    "        else:\n",
    "            return X[self.cols].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carrega dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T03:58:29.453478Z",
     "start_time": "2019-07-14T03:58:29.438474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print shape df_train_val: (891, 12)\n",
      "Print shape df_test: (418, 11)\n"
     ]
    }
   ],
   "source": [
    "df_train_val = pd.read_csv(\"./data/train.csv\")\n",
    "df_test = pd.read_csv(\"./data/test.csv\")\n",
    "df_train_val.columns = [x.lower() for x in df_train_val.columns]\n",
    "df_test.columns = [x.lower() for x in df_test.columns]\n",
    "\n",
    "print(f'Print shape df_train_val: {df_train_val.shape}')\n",
    "print(f'Print shape df_test: {df_test.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação de algumas features novas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tamanho de família"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T03:58:30.122760Z",
     "start_time": "2019-07-14T03:58:30.102750Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family_size</th>\n",
       "      <th>size</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>537</td>\n",
       "      <td>0.303538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>161</td>\n",
       "      <td>0.552795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>0.578431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>0.724138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   family_size  size      mean\n",
       "0            1   537  0.303538\n",
       "1            2   161  0.552795\n",
       "2            3   102  0.578431\n",
       "3            4    29  0.724138\n",
       "4            5    15  0.200000\n",
       "5            6    22  0.136364\n",
       "6            7    12  0.333333\n",
       "7            8     6  0.000000\n",
       "8           11     7  0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "family_size\n",
       "1     253\n",
       "2      74\n",
       "3      57\n",
       "4      14\n",
       "5       7\n",
       "6       3\n",
       "7       4\n",
       "8       2\n",
       "11      4\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_data = [df_train_val, df_test]\n",
    "for dataset in full_data:\n",
    "    dataset['family_size'] = 1 + dataset['parch'] + dataset['sibsp']\n",
    "    if 'survived' in dataset.columns:\n",
    "        display(dataset.fillna(-999).groupby('family_size')['survived'].agg(['size', 'mean']).reset_index())\n",
    "    else:\n",
    "        display(dataset.fillna(-999).groupby('family_size').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aparentemente depois de 4 familiares, talvez seja bom juntar depois"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrai o título"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T03:58:30.613214Z",
     "start_time": "2019-07-14T03:58:30.590185Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>size</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sir</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Countess</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ms</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mme</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lady</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mlle</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mrs</td>\n",
       "      <td>125</td>\n",
       "      <td>0.792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Miss</td>\n",
       "      <td>182</td>\n",
       "      <td>0.697802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Master</td>\n",
       "      <td>40</td>\n",
       "      <td>0.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Col</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Major</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dr</td>\n",
       "      <td>7</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mr</td>\n",
       "      <td>517</td>\n",
       "      <td>0.156673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jonkheer</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Don</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Rev</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Capt</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title  size      mean\n",
       "16       Sir     1  1.000000\n",
       "2   Countess     1  1.000000\n",
       "14        Ms     1  1.000000\n",
       "11       Mme     1  1.000000\n",
       "6       Lady     1  1.000000\n",
       "10      Mlle     2  1.000000\n",
       "13       Mrs   125  0.792000\n",
       "9       Miss   182  0.697802\n",
       "8     Master    40  0.575000\n",
       "1        Col     2  0.500000\n",
       "7      Major     2  0.500000\n",
       "4         Dr     7  0.428571\n",
       "12        Mr   517  0.156673\n",
       "5   Jonkheer     1  0.000000\n",
       "3        Don     1  0.000000\n",
       "15       Rev     6  0.000000\n",
       "0       Capt     1  0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "title\n",
       "Col         2\n",
       "Dona        1\n",
       "Dr          1\n",
       "Master     21\n",
       "Miss       78\n",
       "Mr        240\n",
       "Mrs        72\n",
       "Ms          1\n",
       "Rev         2\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_data = [df_train_val, df_test]\n",
    "for dataset in full_data:\n",
    "    dataset['title'] = dataset['name'].str.findall('([A-Z][a-z]+)\\.').map(lambda x: x[0])\n",
    "    if 'survived' in dataset.columns:\n",
    "        display(dataset.fillna(-999).groupby('title')['survived'].agg(['size', 'mean']).reset_index().sort_values(by='mean', ascending=False))\n",
    "    else:\n",
    "        display(dataset.fillna(-999).groupby('title').size())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T02:19:52.456496Z",
     "start_time": "2019-07-09T02:19:52.417461Z"
    }
   },
   "source": [
    "## Acha aspas ou parênteses no nome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T03:58:32.575452Z",
     "start_time": "2019-07-14T03:58:32.534414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_aspas</th>\n",
       "      <th>size</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.716981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>838</td>\n",
       "      <td>0.362768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name_aspas  size      mean\n",
       "1           1    53  0.716981\n",
       "0           0   838  0.362768"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_parenteses</th>\n",
       "      <th>size</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>748</td>\n",
       "      <td>0.310160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name_parenteses  size      mean\n",
       "1                1   143  0.769231\n",
       "0                0   748  0.310160"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "name_aspas\n",
       "0    396\n",
       "1     22\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "name_parenteses\n",
       "0    340\n",
       "1     78\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_data = [df_train_val, df_test]\n",
    "for dataset in full_data:\n",
    "    dataset['name_aspas'] = dataset['name'].str.findall('\\\"').map(lambda x: len(x) >= 1 ).astype('int')\n",
    "    dataset['name_parenteses'] = dataset['name'].str.findall('\\(').map(lambda x: len(x) >= 1 ).astype('int')\n",
    "    if 'survived' in dataset.columns:\n",
    "        display(dataset.fillna(-999).groupby('name_aspas')['survived'].agg(['size', 'mean']).reset_index().sort_values(by='mean', ascending=False))\n",
    "        display(dataset.fillna(-999).groupby('name_parenteses')['survived'].agg(['size', 'mean']).reset_index().sort_values(by='mean', ascending=False))\n",
    "    else:\n",
    "        display(dataset.fillna(-999).groupby('name_aspas').size())\n",
    "        display(dataset.fillna(-999).groupby('name_parenteses').size())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separa as amostras para treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T03:58:34.359064Z",
     "start_time": "2019-07-14T03:58:34.350064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print shape df_train: (791, 16)\n",
      "Print shape df_val: (100, 16)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val = train_test_split(df_train_val, test_size = 100, shuffle=True, stratify=df_train_val['survived'], random_state=random_global)\n",
    "print(f'Print shape df_train: {df_train.shape}')\n",
    "print(f'Print shape df_val: {df_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T03:38:06.308453Z",
     "start_time": "2019-06-28T03:38:06.304449Z"
    }
   },
   "source": [
    "# Definição do pipeline básico a ser otimizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T03:58:39.112384Z",
     "start_time": "2019-07-14T03:58:39.109390Z"
    }
   },
   "outputs": [],
   "source": [
    "num_cols = ['age', 'sibsp', 'parch', 'fare', 'family_size']\n",
    "cat_cols = ['sex', 'embarked', 'title', 'name_aspas', 'name_parenteses', 'pclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T03:58:40.287451Z",
     "start_time": "2019-07-14T03:58:40.285458Z"
    }
   },
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T05:06:24.719289Z",
     "start_time": "2019-07-14T05:06:24.715286Z"
    }
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "hp_space_lgb ={\n",
    "        'num_missing_strategy': hp.choice('num_missing_strategy', ['mean', 'median', 'constant']),\n",
    "        'categ_encoder': hp.choice('categ_encoder', [WOEEncoder(cols=cat_cols, return_df=True, hp.choice())\n",
    "                                                 ,OneHotEncoder(cols=cat_cols, use_cat_names=True, return_df=True)\n",
    "                                                 ,TargetEncoder(cols=cat_cols, return_df=True)])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T05:15:17.869524Z",
     "start_time": "2019-07-14T05:15:17.851498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (632,)\n",
      "test (159,)\n",
      "train (632,)\n",
      "test (159,)\n",
      "train (633,)\n",
      "test (158,)\n",
      "train (633,)\n",
      "test (158,)\n",
      "train (634,)\n",
      "test (157,)\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(df_train, df_train['survived']):\n",
    "    print('train', train_index.shape)\n",
    "    print('test', test_index.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sklearn_novo]",
   "language": "python",
   "name": "conda-env-sklearn_novo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
