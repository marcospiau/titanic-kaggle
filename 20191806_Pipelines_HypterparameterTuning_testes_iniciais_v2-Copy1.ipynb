{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Definições-iniciais\" data-toc-modified-id=\"Definições-iniciais-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Definições iniciais</a></span><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Configurando-random-pra-deixar-reprodutível\" data-toc-modified-id=\"Configurando-random-pra-deixar-reprodutível-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Configurando random pra deixar reprodutível</a></span></li></ul></li><li><span><a href=\"#Funções-úteis\" data-toc-modified-id=\"Funções-úteis-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Funções úteis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Função-pra-submeter-os-resultados-e-salvar-os-arquivos-necessários-pra-replicar\" data-toc-modified-id=\"Função-pra-submeter-os-resultados-e-salvar-os-arquivos-necessários-pra-replicar-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Função pra submeter os resultados e salvar os arquivos necessários pra replicar</a></span></li><li><span><a href=\"#Custom-transformers\" data-toc-modified-id=\"Custom-transformers-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Custom transformers</a></span></li></ul></li><li><span><a href=\"#Carrega-dados\" data-toc-modified-id=\"Carrega-dados-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Carrega dados</a></span></li><li><span><a href=\"#Criação-de-algumas-features-novas\" data-toc-modified-id=\"Criação-de-algumas-features-novas-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Criação de algumas features novas</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tamanho-de-família\" data-toc-modified-id=\"Tamanho-de-família-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Tamanho de família</a></span></li><li><span><a href=\"#Extrai-o-título\" data-toc-modified-id=\"Extrai-o-título-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Extrai o título</a></span></li><li><span><a href=\"#Acha-aspas-ou-parênteses-no-nome\" data-toc-modified-id=\"Acha-aspas-ou-parênteses-no-nome-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Acha aspas ou parênteses no nome</a></span></li></ul></li><li><span><a href=\"#Definição-do-pipeline-básico-a-ser-otimizado\" data-toc-modified-id=\"Definição-do-pipeline-básico-a-ser-otimizado-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Definição do pipeline básico a ser otimizado</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tratamento-de-categóricas-(transforma-pra-pandas-tipo-categórico-e-garante-mesmas-categorias-no-treino-e-no-teste)\" data-toc-modified-id=\"Tratamento-de-categóricas-(transforma-pra-pandas-tipo-categórico-e-garante-mesmas-categorias-no-treino-e-no-teste)-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Tratamento de categóricas (transforma pra pandas tipo categórico e garante mesmas categorias no treino e no teste)</a></span></li><li><span><a href=\"#Separa-as-amostras-para-treino-e-validação\" data-toc-modified-id=\"Separa-as-amostras-para-treino-e-validação-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Separa as amostras para treino e validação</a></span></li></ul></li><li><span><a href=\"#Usando-lgbm-sem-interface-sklearn\" data-toc-modified-id=\"Usando-lgbm-sem-interface-sklearn-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Usando lgbm sem interface sklearn</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T03:51:38.029819Z",
     "start_time": "2019-07-14T03:51:38.026826Z"
    }
   },
   "source": [
    "Vou montar aqui um pipeline mais robusto, mais próximo do produtivo, focando em lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definições iniciais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T03:22:35.912486Z",
     "start_time": "2019-08-09T03:22:35.899475Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer, TransformedTargetRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, RandomizedSearchCV, train_test_split, StratifiedKFold,cross_val_score\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Pandas numpy etc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# Hyperopt\n",
    "from hyperopt import fmin, hp, tpe, rand, Trials, space_eval, STATUS_OK, anneal\n",
    "from hyperopt.pyll import scope as ho_scope\n",
    "from hyperopt.pyll.stochastic import sample as ho_sample\n",
    "from functools import partial\n",
    "\n",
    "# Category encoders\n",
    "# from category_encoders.hashing import HashingEncoder\n",
    "# from category_encoders.sum_coding import SumEncoder\n",
    "# from category_encoders.woe import WOEEncoder\n",
    "# from category_encoders.target_encoder import TargetEncoder\n",
    "# from category_encoders.one_hot import OneHotEncoder\n",
    "# from category_encoders.binary import BinaryEncoder\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Files\n",
    "# Files e utils\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "from joblib import Memory\n",
    "import joblib\n",
    "import os\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurando random pra deixar reprodutível"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:10:51.561256Z",
     "start_time": "2019-08-09T01:10:51.442148Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "random_global = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções úteis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função pra submeter os resultados e salvar os arquivos necessários pra replicar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:10:51.655690Z",
     "start_time": "2019-08-09T01:10:51.562257Z"
    }
   },
   "outputs": [],
   "source": [
    "class SaveModel(object):\n",
    "    def __init__(self, folder_to_save, data_train=None, data_val=None, data_test=None, model=None, str_readme=None, submission_file='submission.csv'):\n",
    "        self.folder_to_save = folder_to_save\n",
    "        self.data_train = data_train\n",
    "        self.data_val = data_val\n",
    "        self.data_test = data_test\n",
    "        self.model = model\n",
    "        self.str_readme = str_readme\n",
    "        self.submission_file = submission_file\n",
    "    \n",
    "    def save_model(self):\n",
    "#     Create folder if not exists:\n",
    "        try:\n",
    "            os.makedirs(self.folder_to_save)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    #     Salva os dados usados no treino\n",
    "        if self.data_train is not None:\n",
    "            joblib.dump(self.data_train, self.folder_to_save+'/train_data')\n",
    "\n",
    "\n",
    "    #     Salva dados usados na validação\n",
    "        if self.data_val is not None:\n",
    "            joblib.dump(self.data_test, self.folder_to_save+'/validation_data')\n",
    "\n",
    "    #     Salva dados usados no teste\n",
    "        if self.data_test is not None:\n",
    "            joblib.dump(self.data_test, self.folder_to_save+'/test_data')\n",
    "\n",
    "    #     Salva modelo \n",
    "        if self.model is not None:\n",
    "            joblib.dump(self.model, self.folder_to_save+'/model')   \n",
    "\n",
    "    #     Arquivo README (é o que vai escrito pro commit)\n",
    "        with open(self.folder_to_save+'/README.txt', \"w\") as text_file:\n",
    "            text_file.write(self.str_readme)\n",
    "            \n",
    "#         Salva os predictions\n",
    "        \n",
    "\n",
    "    def commit_kaggle(self):\n",
    "        predictions = self.model.predict(self.data_test)\n",
    "        submission = pd.DataFrame({'PassengerId':self.data_test['passengerid'],'Survived':predictions})\n",
    "        submission.to_csv(self.folder_to_save+'/'+self.submission_file,index=False)\n",
    "#         print(f\"kaggle competitions submit -c titanic -f submission.csv -m \\\"{self.str_readme}\\\"\")\n",
    "#         !! f\"kaggle competitions submit -c titanic -f {self.folder_to_save+'/'+self.submission_file} -m \\\"{self.str_readme}\\\"\"\n",
    "        if os.system(f\"kaggle competitions submit -c titanic -f {self.folder_to_save+'/'+self.submission_file} -m \\\"{self.str_readme}\\\"\") != 0:\n",
    "            print('Erro submetendo o arquivo no kaggle!')\n",
    "            \n",
    "        print(f\"kaggle competitions submit -c titanic -f {self.folder_to_save+'/'+self.submission_file} -m \\\"{self.str_readme}\\\"\")\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:10:51.780244Z",
     "start_time": "2019-08-09T01:10:51.656691Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from functools import reduce\n",
    "\n",
    "class TransformToDF(BaseEstimator, TransformerMixin):\n",
    "    '''Wrapper para usar transformers do sklearn mas retorna um dataframe Pandas. Projetei para usar com transformers que não\n",
    "    mudam o número de colunas na saída.'''\n",
    "    \n",
    "    def __init__(self, sklearn_transformer, return_df=True):\n",
    "        self.sklearn_transformer = sklearn_transformer\n",
    "        self.return_df = return_df\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            self.col_names = X.columns.values.tolist()\n",
    "            \n",
    "        self.sklearn_transformer.fit(X, y=None)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "    # assumes X is a DataFrame\n",
    "        if self.return_df:\n",
    "            return pd.DataFrame(self.sklearn_transformer.transform(X[self.col_names]), index=X.index, columns=self.col_names)\n",
    "        else:\n",
    "            return self.sklearn_transformer.transform(X)\n",
    "        \n",
    "class DFFeatureUnion(BaseEstimator,TransformerMixin):\n",
    "    # FeatureUnion but for pandas DataFrames\n",
    "\n",
    "    def __init__(self, transformer_list):\n",
    "        self.transformer_list = transformer_list\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for (name, t) in self.transformer_list:\n",
    "            t.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xts = [t.transform(X) for _, t in self.transformer_list]\n",
    "        Xunion = reduce(lambda X1, X2: pd.merge(X1, X2, left_index=True, right_index=True), Xts)\n",
    "        return Xunion\n",
    "    \n",
    "class ColumnExtractor(BaseEstimator,TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols, return_df=True):\n",
    "        self.cols = cols\n",
    "        self.return_df = return_df\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # stateless transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        if self.return_df:\n",
    "            return X[self.cols]\n",
    "        else:\n",
    "            return X[self.cols].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carrega dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:10:51.927880Z",
     "start_time": "2019-08-09T01:10:51.781228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print shape df_train_val: (891, 12)\n",
      "Print shape df_test: (418, 11)\n"
     ]
    }
   ],
   "source": [
    "df_train_val = pd.read_csv(\"./data/train.csv\")\n",
    "df_test = pd.read_csv(\"./data/test.csv\")\n",
    "df_train_val.columns = [x.lower() for x in df_train_val.columns]\n",
    "df_test.columns = [x.lower() for x in df_test.columns]\n",
    "\n",
    "print(f'Print shape df_train_val: {df_train_val.shape}')\n",
    "print(f'Print shape df_test: {df_test.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação de algumas features novas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tamanho de família"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:10:52.035264Z",
     "start_time": "2019-08-09T01:10:51.928882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family_size</th>\n",
       "      <th>size</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>537</td>\n",
       "      <td>0.303538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>161</td>\n",
       "      <td>0.552795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>0.578431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>0.724138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   family_size  size      mean\n",
       "0            1   537  0.303538\n",
       "1            2   161  0.552795\n",
       "2            3   102  0.578431\n",
       "3            4    29  0.724138\n",
       "4            5    15  0.200000\n",
       "5            6    22  0.136364\n",
       "6            7    12  0.333333\n",
       "7            8     6  0.000000\n",
       "8           11     7  0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "family_size\n",
       "1     253\n",
       "2      74\n",
       "3      57\n",
       "4      14\n",
       "5       7\n",
       "6       3\n",
       "7       4\n",
       "8       2\n",
       "11      4\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_data = [df_train_val, df_test]\n",
    "for dataset in full_data:\n",
    "    dataset['family_size'] = 1 + dataset['parch'] + dataset['sibsp']\n",
    "    if 'survived' in dataset.columns:\n",
    "        display(dataset.fillna(-999).groupby('family_size')['survived'].agg(['size', 'mean']).reset_index())\n",
    "    else:\n",
    "        display(dataset.fillna(-999).groupby('family_size').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aparentemente depois de 4 familiares, talvez seja bom juntar depois"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrai o título"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:10:52.235689Z",
     "start_time": "2019-08-09T01:10:52.036255Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>size</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sir</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Countess</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ms</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mme</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lady</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mlle</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mrs</td>\n",
       "      <td>125</td>\n",
       "      <td>0.792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Miss</td>\n",
       "      <td>182</td>\n",
       "      <td>0.697802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Master</td>\n",
       "      <td>40</td>\n",
       "      <td>0.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Col</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Major</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dr</td>\n",
       "      <td>7</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mr</td>\n",
       "      <td>517</td>\n",
       "      <td>0.156673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jonkheer</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Don</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Rev</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Capt</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title  size      mean\n",
       "16       Sir     1  1.000000\n",
       "2   Countess     1  1.000000\n",
       "14        Ms     1  1.000000\n",
       "11       Mme     1  1.000000\n",
       "6       Lady     1  1.000000\n",
       "10      Mlle     2  1.000000\n",
       "13       Mrs   125  0.792000\n",
       "9       Miss   182  0.697802\n",
       "8     Master    40  0.575000\n",
       "1        Col     2  0.500000\n",
       "7      Major     2  0.500000\n",
       "4         Dr     7  0.428571\n",
       "12        Mr   517  0.156673\n",
       "5   Jonkheer     1  0.000000\n",
       "3        Don     1  0.000000\n",
       "15       Rev     6  0.000000\n",
       "0       Capt     1  0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "title\n",
       "Col         2\n",
       "Dona        1\n",
       "Dr          1\n",
       "Master     21\n",
       "Miss       78\n",
       "Mr        240\n",
       "Mrs        72\n",
       "Ms          1\n",
       "Rev         2\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_data = [df_train_val, df_test]\n",
    "for dataset in full_data:\n",
    "    dataset['title'] = dataset['name'].str.findall('([A-Z][a-z]+)\\.').map(lambda x: x[0])\n",
    "    if 'survived' in dataset.columns:\n",
    "        display(dataset.fillna(-999).groupby('title')['survived'].agg(['size', 'mean']).reset_index().sort_values(by='mean', ascending=False))\n",
    "    else:\n",
    "        display(dataset.fillna(-999).groupby('title').size())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T02:19:52.456496Z",
     "start_time": "2019-07-09T02:19:52.417461Z"
    }
   },
   "source": [
    "## Acha aspas ou parênteses no nome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:10:58.072909Z",
     "start_time": "2019-08-09T01:10:58.033873Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_aspas</th>\n",
       "      <th>size</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.716981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>838</td>\n",
       "      <td>0.362768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name_aspas  size      mean\n",
       "1           1    53  0.716981\n",
       "0           0   838  0.362768"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_parenteses</th>\n",
       "      <th>size</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>748</td>\n",
       "      <td>0.310160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name_parenteses  size      mean\n",
       "1                1   143  0.769231\n",
       "0                0   748  0.310160"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "name_aspas\n",
       "0    396\n",
       "1     22\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "name_parenteses\n",
       "0    340\n",
       "1     78\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_data = [df_train_val, df_test]\n",
    "for dataset in full_data:\n",
    "    dataset['name_aspas'] = dataset['name'].str.findall('\\\"').map(lambda x: len(x) >= 1 ).astype('int')\n",
    "    dataset['name_parenteses'] = dataset['name'].str.findall('\\(').map(lambda x: len(x) >= 1 ).astype('int')\n",
    "    if 'survived' in dataset.columns:\n",
    "        display(dataset.fillna(-999).groupby('name_aspas')['survived'].agg(['size', 'mean']).reset_index().sort_values(by='mean', ascending=False))\n",
    "        display(dataset.fillna(-999).groupby('name_parenteses')['survived'].agg(['size', 'mean']).reset_index().sort_values(by='mean', ascending=False))\n",
    "    else:\n",
    "        display(dataset.fillna(-999).groupby('name_aspas').size())\n",
    "        display(dataset.fillna(-999).groupby('name_parenteses').size())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definição do pipeline básico a ser otimizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento de categóricas (transforma pra pandas tipo categórico e garante mesmas categorias no treino e no teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:11:00.004945Z",
     "start_time": "2019-08-09T01:11:00.001943Z"
    }
   },
   "outputs": [],
   "source": [
    "num_cols = ['age', 'sibsp', 'parch', 'fare', 'family_size']\n",
    "cat_cols = ['sex', 'embarked', 'title', 'name_aspas', 'name_parenteses', 'pclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:11:00.700918Z",
     "start_time": "2019-08-09T01:11:00.690918Z"
    }
   },
   "outputs": [],
   "source": [
    "dict_dtypes = {}\n",
    "for col in cat_cols + num_cols:\n",
    "    if col in cat_cols:\n",
    "        dict_dtypes[col] = CategoricalDtype(categories=df_train_val[col].dropna().unique(), ordered=False)\n",
    "    else:\n",
    "        dict_dtypes[col] = df_train_val[col].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:11:03.886652Z",
     "start_time": "2019-08-09T01:11:03.876634Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_val = df_train_val.astype(dict_dtypes)\n",
    "df_test = df_test.astype(dict_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:19:15.286941Z",
     "start_time": "2019-08-09T01:19:15.266925Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>embarked</th>\n",
       "      <th>title</th>\n",
       "      <th>name_aspas</th>\n",
       "      <th>name_parenteses</th>\n",
       "      <th>pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sex  embarked  title  name_aspas  name_parenteses  pclass\n",
       "0      0         0      0           0                0       0\n",
       "1      1         1      1           0                1       1\n",
       "2      1         0      2           0                0       0\n",
       "3      1         0      1           0                1       1\n",
       "4      0         0      0           0                0       0\n",
       "5      0         2      0           0                0       0\n",
       "6      0         0      0           0                0       1\n",
       "7      0         0      3           0                0       0\n",
       "8      1         0      1           0                1       0\n",
       "9      1         1      1           0                1       2\n",
       "10     1         0      2           0                0       0\n",
       "11     1         0      2           0                0       1\n",
       "12     0         0      0           0                0       0\n",
       "13     0         0      0           0                0       0\n",
       "14     1         0      2           0                0       0\n",
       "15     1         0      1           0                1       2\n",
       "16     0         2      3           0                0       0\n",
       "17     0         0      0           0                0       2\n",
       "18     1         0      1           0                1       0\n",
       "19     1         1      1           0                0       0\n",
       "20     0         0      0           0                0       2\n",
       "21     0         0      0           0                0       2\n",
       "22     1         2      2           1                0       0\n",
       "23     0         0      0           0                0       1\n",
       "24     1         0      2           0                0       0\n",
       "25     1         0      1           0                1       0\n",
       "26     0         1      0           0                0       0\n",
       "27     0         0      0           0                0       1\n",
       "28     1         2      2           1                0       0\n",
       "29     0         0      0           0                0       0\n",
       "..   ...       ...    ...         ...              ...     ...\n",
       "861    0         0      0           0                0       2\n",
       "862    1         0      1           0                1       1\n",
       "863    1         0      2           1                0       0\n",
       "864    0         0      0           0                0       2\n",
       "865    1         0      1           0                1       2\n",
       "866    1         1      2           0                0       2\n",
       "867    0         0      0           0                0       1\n",
       "868    0         0      0           0                0       0\n",
       "869    0         0      3           0                0       0\n",
       "870    0         0      0           0                0       0\n",
       "871    1         0      1           0                1       1\n",
       "872    0         0      0           0                0       1\n",
       "873    0         0      0           0                0       0\n",
       "874    1         1      1           0                1       2\n",
       "875    1         1      2           1                0       0\n",
       "876    0         0      0           0                0       0\n",
       "877    0         0      0           0                0       0\n",
       "878    0         0      0           0                0       0\n",
       "879    1         1      1           0                1       1\n",
       "880    1         0      1           0                1       2\n",
       "881    0         0      0           0                0       0\n",
       "882    1         0      2           0                0       0\n",
       "883    0         0      0           0                0       2\n",
       "884    0         0      0           0                0       0\n",
       "885    1         2      1           0                1       0\n",
       "886    0         0      5           0                0       2\n",
       "887    1         0      2           0                0       1\n",
       "888    1         0      2           1                0       0\n",
       "889    0         1      0           0                0       1\n",
       "890    0         2      0           0                0       0\n",
       "\n",
       "[891 rows x 6 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_val[cat_cols].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separa as amostras para treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T03:53:08.160131Z",
     "start_time": "2019-08-09T03:53:08.151133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print shape df_train: (791, 16)\n",
      "Print shape df_val: (100, 16)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val = train_test_split(df_train_val, test_size = 100, shuffle=True, stratify=df_train_val['survived'], random_state=random_global)\n",
    "print(f'Print shape df_train: {df_train.shape}')\n",
    "print(f'Print shape df_val: {df_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:12:21.526105Z",
     "start_time": "2019-08-09T01:12:21.522111Z"
    }
   },
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T05:04:46.457294Z",
     "start_time": "2019-08-09T05:04:46.426257Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>embarked</th>\n",
       "      <th>title</th>\n",
       "      <th>name_aspas</th>\n",
       "      <th>name_parenteses</th>\n",
       "      <th>pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>577</td>\n",
       "      <td>644</td>\n",
       "      <td>517</td>\n",
       "      <td>838</td>\n",
       "      <td>748</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sex  embarked  title  name_aspas  name_parenteses  pclass\n",
       "count   891       891    891         891              891     891\n",
       "unique    2         4     17           2                2       3\n",
       "top       0         0      0           0                0       0\n",
       "freq    577       644    517         838              748     491"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_cat_codes(X, return_df=False, return_as_category=False):\n",
    "    if return_df:\n",
    "        if return_as_category:\n",
    "            return X.apply(lambda x: x.cat.codes).astype('category')\n",
    "        else:\n",
    "            return X.apply(lambda x: x.cat.codes)\n",
    "    else:\n",
    "        return X.apply(lambda x: x.cat.codes).values\n",
    "get_cat_codes(df_train_val[cat_cols], return_df=True, return_as_category=True).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T04:41:53.701409Z",
     "start_time": "2019-08-09T04:41:53.688387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex                category\n",
       "embarked           category\n",
       "title              category\n",
       "name_aspas         category\n",
       "name_parenteses    category\n",
       "pclass             category\n",
       "dtype: object"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_pipeline(FunctionTransformer(get_cat_codes, validate=False, kw_args={'return_df':True, 'return_as_category':True}))\\\n",
    ".fit_transform(df_train_val[cat_cols]).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T04:56:09.642065Z",
     "start_time": "2019-08-09T04:56:09.634057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.10231279,  0.43279337, -0.47367361, -0.50244517,  0.05915988],\n",
       "       [ 0.80749164,  0.43279337, -0.47367361,  0.78684529,  0.05915988],\n",
       "       [ 0.12513832, -0.4745452 , -0.47367361, -0.48885426, -0.56097483],\n",
       "       ...,\n",
       "       [-1.35329389,  0.43279337,  2.00893337, -0.17626324,  1.29942929],\n",
       "       [ 0.12513832, -0.4745452 , -0.47367361, -0.04438104, -0.56097483],\n",
       "       [ 0.46631498, -0.4745452 , -0.47367361, -0.49237783, -0.56097483]])"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_pipeline(ColumnExtractor(num_cols, return_df=False), TransformToDF(SimpleImputer(fill_value=0, strategy='constant')\\\n",
    "                                                                        ,return_df=False)\\\n",
    "              ,TransformToDF(StandardScaler(), return_df=False))\\\n",
    ".fit_transform(df_train_val[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T05:22:27.832907Z",
     "start_time": "2019-08-09T05:22:27.802882Z"
    }
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "def f_wrap_space_eval(hp_space, trial):\n",
    "    \"\"\"\n",
    "    Utility function for more consise optimization history extraction\n",
    "    \n",
    "    Parameters:\n",
    "    ----------------\n",
    "    hp_space : hyperspace from which points are sampled\n",
    "    trial : hyperopt.Trials object\n",
    "    \n",
    "    Returns:\n",
    "    ----------------\n",
    "    : dict(\n",
    "        k: v\n",
    "    ), where k - label of hyperparameter, v - value of hyperparameter in trial\n",
    "    \"\"\"\n",
    "    \n",
    "    return space_eval(hp_space, {k: v[0] for (k, v) in trial['misc']['vals'].items() if len(v) > 0})\n",
    "\n",
    "\n",
    "def f_unpack_dict(dct):\n",
    "    \"\"\"\n",
    "    Unpacks all sub-dictionaries in given dictionary recursively. There should be no duplicated keys \n",
    "    across all nested subdictionaries, or some instances will be lost without warning\n",
    "    \n",
    "    Parameters:\n",
    "    ----------------\n",
    "    dct : dictionary to unpack\n",
    "    \n",
    "    Returns:\n",
    "    ----------------\n",
    "    : unpacked dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    res = {}\n",
    "    for (k, v) in dct.items():\n",
    "        if isinstance(v, dict):\n",
    "            res = {**res, **f_unpack_dict(v)}\n",
    "        else:\n",
    "            res[k] = v\n",
    "            \n",
    "    return res\n",
    "\n",
    "# Função a ser minimizada\n",
    "def f_to_min1(hps, X, y, cv):\n",
    "    \"\"\"\n",
    "    Target function for optimization\n",
    "    \n",
    "    Parameters:\n",
    "    ----------------\n",
    "    hps : sample point from search space\n",
    "    X : feature matrix\n",
    "    y : target array\n",
    "    ncv : number of folds for cross-validation\n",
    "    \n",
    "    Returns:\n",
    "    ----------------\n",
    "    : target function value (negative mean cross-val ROC-AUC score)\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    model = get_pipeline(hps)\n",
    "    crossval = cross_validate(model, X, y, return_train_score=True, cv=cv, scoring='roc_auc')\n",
    "\n",
    "    return {'loss': -crossval['test_score'].mean(), 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "hp_space_lgb ={\n",
    "    'num_missing_strategy': hp.choice('num_missing_strategy', ['mean', 'median', 'constant']),\n",
    "#     'categ_encoder': hp.choice('categ_encoder', ['woe','one_hot','target_encoder', 'lgbm_internal']),\n",
    "    'categ_encoder': hp.choice('categ_encoder', ['one_hot','label_encoder', 'lgbm_internal']),\n",
    "        # type refers to classifier type: either logit or SVM\n",
    "    'clf_type': hp.choice('clf_type', [\n",
    "        {\n",
    "            'type': 'logit',\n",
    "            'clf': {\n",
    "                'C': hp.loguniform('logit.C', -4.0*np.log(10.0), 4.0*np.log(10.0)), \n",
    "                'class_weight': hp.choice('logit.class_weight', [None, 'balanced'])\n",
    "            }\n",
    "        }, \n",
    "        {\n",
    "            'type': 'SVM', \n",
    "            'clf': {\n",
    "                'C': hp.loguniform('svm.C', -4.0*np.log(10.0), 4.0*np.log(10.0)), \n",
    "                'class_weight': hp.choice('svm.class_weight', [None, 'balanced']), \n",
    "                'kernel': 'rbf', \n",
    "                'gamma': hp.choice('svm.gamma', ['auto', 'scale'])\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'type': 'lgbm_rf',\n",
    "            'clf': {\n",
    "                'max_depth': ho_scope.int(hp.uniform('lgbm_rf.max_depth', low=1, high=11)),\n",
    "                'boosting_type': \"rf\",\n",
    "                'num_leaves': 165,\n",
    "                'colsample_bytree': .5,\n",
    "                'n_estimators': 2000,\n",
    "                'min_child_weight': 0,\n",
    "                'min_child_samples':0,\n",
    "                'subsample': .632, # Standard RF bagging fraction\n",
    "                'subsample_freq': 1,\n",
    "                'min_split_gain': 0,\n",
    "                'reg_alpha': 0, \n",
    "                'reg_lambda': 0,\n",
    "                'subsample_for_bin':200000,\n",
    "                'min_data_per_group': 5\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'type': 'RandomForest', \n",
    "            'clf': {\n",
    "                    'bootstrap': hp.choice('rf.bootstrap', [False, True]),\n",
    "                    'class_weight': hp.choice('rf.class_weight',['balanced', 'balanced_subsample', None]),\n",
    "                    'criterion': hp.choice('rf.criterion', ['gini', 'entropy']),\n",
    "                    'max_depth': ho_scope.int(hp.uniform('rf.max_depth', low=1, high=11)),\n",
    "                    'max_features': hp.choice('rf.max_features', ['auto','sqrt', None]),\n",
    "                    'max_leaf_nodes': ho_scope.int(hp.uniform('rf.max_leaf_nodes', low=2, high=1024)),\n",
    "                    'min_samples_split': ho_scope.int(hp.uniform('rf.min_samples_split', low=2, high=1024)),\n",
    "                    'min_weight_fraction_leaf': 0.1 * ho_scope.int(hp.uniform('rf.min_weight_fraction_leaf', low=0, high=5)),\n",
    "                    'n_estimators': 100 * ho_scope.int(hp.uniform('rf.n_estimators', low=1, high=10)),\n",
    "                    'oob_score': False\n",
    "            }\n",
    "        }\n",
    "    ])\n",
    "}\n",
    "\n",
    "\n",
    "def get_pipeline(hps, use_df=True):\n",
    "    \"\"\"\n",
    "    Constructs estimator\n",
    "    \n",
    "    Parameters:\n",
    "    ----------------\n",
    "    hps : sample point from search space\n",
    "    use_df: if Pandas Dataframes should be used. \n",
    "    Can reduce speed but maybe necessary for interpretability or other reasons.\n",
    "    \n",
    "    Returns:\n",
    "    ----------------\n",
    "    model : sklearn.Pipeline.pipeline with hyperparameters set up as per hps\n",
    "    \"\"\"\n",
    "    \n",
    "#     Escolha de encoder\n",
    "    if hps['categ_encoder'] == 'one_hot':\n",
    "        kwargs_get_cat_codes={'return_df':use_df, 'return_as_category':False}\n",
    "        categ_encoder = OneHotEncoder(categories='auto', sparse=False)\n",
    "    elif hps['categ_encoder'] == 'label_encoder':\n",
    "        kwargs_get_cat_codes={'return_df':use_df, 'return_as_category':False}\n",
    "        categ_encoder = None\n",
    "#     'lgbm_internal' só vai fazer diferença pro lgbm, pros restantes vai ser idêntico a um label_encoder\n",
    "    # Por enquanto aqui vai precisar usar pandas se quiser usar as features categóricas no lgbm\n",
    "    elif hps['categ_encoder'] == 'lgbm_internal':\n",
    "        kwargs_get_cat_codes={'return_df':use_df, 'return_as_category':True}\n",
    "        categ_encoder = None\n",
    "    \n",
    "    cat_pipeline = make_pipeline(ColumnExtractor(cat_cols, return_df=use_df),\\\n",
    "                                 FunctionTransformer(get_cat_codes, validate=False, kw_args=kwargs_get_cat_codes))\n",
    "    \n",
    "#     Para logística precisaremos normalizar as features\n",
    "    if hps['clf_type']['type'] == 'logit':\n",
    "        num_pipeline = make_pipeline(ColumnExtractor(num_cols, return_df=use_df),\\\n",
    "                                     TransformToDF(SimpleImputer(fill_value=0, strategy=hps['num_missing_strategy']),\\\n",
    "                                                   return_df=use_df),TransformToDF(StandardScaler(), return_df=use_df))\n",
    "    else:\n",
    "        num_pipeline = make_pipeline(ColumnExtractor(num_cols, return_df=use_df),\\\n",
    "                                     TransformToDF(SimpleImputer(fill_value=0, strategy=hps['num_missing_strategy']),\\\n",
    "                                                   return_df=use_df))\n",
    "    \n",
    "    if hps['clf_type']['type'] == 'logit':\n",
    "        clf = LogisticRegression(**hps['clf_type']['clf'], solver='sag', max_iter=25000, random_state=random_global)\n",
    "    elif hps['clf_type']['type'] == 'SVM':\n",
    "        clf = SVC(**f_unpack_dict(hps['clf_type']['clf']), probability=True, random_state=random_global)\n",
    "    elif hps['clf_type']['type'] == 'RandomForest':\n",
    "        clf = RandomForestClassifier(**f_unpack_dict(hps['clf_type']['clf']), random_state=random_global)\n",
    "    elif hps['clf_type']['type'] == 'lgbm_rf':\n",
    "        clf = LGBMClassifier(**f_unpack_dict(hps['clf_type']['clf']), random_state=random_global)\n",
    "    else:\n",
    "        raise KeyError('Unknown classifier type hyperparameter value: {0}'.format(hps['clf_type']['type']))\n",
    "    \n",
    "    \n",
    "    model = Pipeline([('features', DFFeatureUnion([('cat_flow',cat_pipeline), ('num_flow',num_pipeline)])), ('clf', clf)])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T05:23:19.853639Z",
     "start_time": "2019-08-09T05:22:30.101467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 3/3 [00:49<00:00, 12.85s/it, best loss: -0.8861751508107044]\n"
     ]
    }
   ],
   "source": [
    "trials_clf1 = Trials()\n",
    "\n",
    "best_clf1=fmin(partial(f_to_min1,X=df_train, y=df_train['survived'], cv=kf)\n",
    "     ,hp_space_lgb, algo=tpe.suggest, max_evals=3, trials=trials_clf1, rstate=np.random.RandomState(random_global))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T05:26:40.321188Z",
     "start_time": "2019-08-09T05:26:40.315192Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'categ_encoder': 'label_encoder',\n",
       " 'clf_type': {'clf': {'boosting_type': 'rf',\n",
       "   'colsample_bytree': 0.5,\n",
       "   'max_depth': 10,\n",
       "   'min_child_samples': 0,\n",
       "   'min_child_weight': 0,\n",
       "   'min_data_per_group': 5,\n",
       "   'min_split_gain': 0,\n",
       "   'n_estimators': 2000,\n",
       "   'num_leaves': 165,\n",
       "   'reg_alpha': 0,\n",
       "   'reg_lambda': 0,\n",
       "   'subsample': 0.632,\n",
       "   'subsample_for_bin': 200000,\n",
       "   'subsample_freq': 1},\n",
       "  'type': 'lgbm_rf'},\n",
       " 'num_missing_strategy': 'median'}"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space_eval(hp_space_lgb, best_clf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T05:26:42.331946Z",
     "start_time": "2019-08-09T05:26:42.299926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('features',\n",
       "                 DFFeatureUnion(transformer_list=[('cat_flow',\n",
       "                                                   Pipeline(memory=None,\n",
       "                                                            steps=[('columnextractor',\n",
       "                                                                    ColumnExtractor(cols=['sex',\n",
       "                                                                                          'embarked',\n",
       "                                                                                          'title',\n",
       "                                                                                          'name_aspas',\n",
       "                                                                                          'name_parenteses',\n",
       "                                                                                          'pclass'],\n",
       "                                                                                    return_df=True)),\n",
       "                                                                   ('functiontransformer',\n",
       "                                                                    FunctionTransformer(accept_sparse=False,\n",
       "                                                                                        check_inverse=True,\n",
       "                                                                                        func=<function get_cat_codes at 0x...\n",
       "                 LGBMClassifier(boosting_type='rf', class_weight=None,\n",
       "                                colsample_bytree=0.5, importance_type='split',\n",
       "                                learning_rate=0.1, max_depth=10,\n",
       "                                min_child_samples=0, min_child_weight=0,\n",
       "                                min_data_per_group=5, min_split_gain=0,\n",
       "                                n_estimators=2000, n_jobs=-1, num_leaves=165,\n",
       "                                objective=None, random_state=42, reg_alpha=0,\n",
       "                                reg_lambda=0, silent=True, subsample=0.632,\n",
       "                                subsample_for_bin=200000, subsample_freq=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pipeline(space_eval(hp_space_lgb, best_clf1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T03:27:04.159352Z",
     "start_time": "2019-08-09T03:27:04.155348Z"
    }
   },
   "source": [
    "# Usando lgbm sem interface sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T03:50:25.887047Z",
     "start_time": "2019-08-09T03:50:25.884054Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T04:30:25.873754Z",
     "start_time": "2019-08-09T04:30:25.664563Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\T-Gamer\\Anaconda3\\envs\\sklearn_novo\\lib\\site-packages\\lightgbm\\engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\T-Gamer\\Anaconda3\\envs\\sklearn_novo\\lib\\site-packages\\lightgbm\\basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain's auc: 0.88935\teval's auc: 0.819397\n",
      "[2]\ttrain's auc: 0.906757\teval's auc: 0.822368\n",
      "[3]\ttrain's auc: 0.900694\teval's auc: 0.837012\n",
      "[4]\ttrain's auc: 0.906952\teval's auc: 0.837861\n",
      "[5]\ttrain's auc: 0.906426\teval's auc: 0.837649\n",
      "[6]\ttrain's auc: 0.907709\teval's auc: 0.836375\n",
      "[7]\ttrain's auc: 0.907969\teval's auc: 0.843591\n",
      "[8]\ttrain's auc: 0.911319\teval's auc: 0.844864\n",
      "[9]\ttrain's auc: 0.910603\teval's auc: 0.842742\n",
      "[10]\ttrain's auc: 0.911269\teval's auc: 0.841469\n",
      "[11]\ttrain's auc: 0.910472\teval's auc: 0.838922\n",
      "[12]\ttrain's auc: 0.911231\teval's auc: 0.832131\n",
      "[13]\ttrain's auc: 0.912731\teval's auc: 0.840195\n",
      "[14]\ttrain's auc: 0.912204\teval's auc: 0.841044\n",
      "[15]\ttrain's auc: 0.913322\teval's auc: 0.835102\n",
      "[16]\ttrain's auc: 0.912815\teval's auc: 0.841469\n",
      "[17]\ttrain's auc: 0.914524\teval's auc: 0.844864\n",
      "[18]\ttrain's auc: 0.913423\teval's auc: 0.84444\n",
      "[19]\ttrain's auc: 0.913933\teval's auc: 0.849958\n",
      "[20]\ttrain's auc: 0.91394\teval's auc: 0.847835\n",
      "[21]\ttrain's auc: 0.914271\teval's auc: 0.849958\n",
      "[22]\ttrain's auc: 0.915629\teval's auc: 0.84444\n",
      "[23]\ttrain's auc: 0.916014\teval's auc: 0.840195\n",
      "[24]\ttrain's auc: 0.916385\teval's auc: 0.84062\n",
      "[25]\ttrain's auc: 0.916932\teval's auc: 0.841469\n",
      "[26]\ttrain's auc: 0.917567\teval's auc: 0.839771\n",
      "[27]\ttrain's auc: 0.916804\teval's auc: 0.843591\n",
      "[28]\ttrain's auc: 0.916902\teval's auc: 0.842742\n",
      "[29]\ttrain's auc: 0.916118\teval's auc: 0.847411\n",
      "[30]\ttrain's auc: 0.916159\teval's auc: 0.847411\n",
      "[31]\ttrain's auc: 0.915551\teval's auc: 0.849958\n",
      "[32]\ttrain's auc: 0.915713\teval's auc: 0.84826\n",
      "[33]\ttrain's auc: 0.915953\teval's auc: 0.847411\n",
      "[34]\ttrain's auc: 0.915561\teval's auc: 0.850382\n",
      "[35]\ttrain's auc: 0.91569\teval's auc: 0.850382\n",
      "[36]\ttrain's auc: 0.915467\teval's auc: 0.852504\n",
      "[37]\ttrain's auc: 0.915007\teval's auc: 0.853353\n",
      "[38]\ttrain's auc: 0.91446\teval's auc: 0.85208\n",
      "[39]\ttrain's auc: 0.914149\teval's auc: 0.853353\n",
      "[40]\ttrain's auc: 0.913933\teval's auc: 0.852929\n",
      "[41]\ttrain's auc: 0.913798\teval's auc: 0.855051\n",
      "[42]\ttrain's auc: 0.91421\teval's auc: 0.855051\n",
      "[43]\ttrain's auc: 0.914264\teval's auc: 0.854202\n",
      "[44]\ttrain's auc: 0.914339\teval's auc: 0.856324\n",
      "[45]\ttrain's auc: 0.914447\teval's auc: 0.856324\n",
      "[46]\ttrain's auc: 0.914183\teval's auc: 0.855051\n",
      "[47]\ttrain's auc: 0.914697\teval's auc: 0.857173\n",
      "[48]\ttrain's auc: 0.915608\teval's auc: 0.856749\n",
      "[49]\ttrain's auc: 0.915136\teval's auc: 0.856749\n",
      "[50]\ttrain's auc: 0.915176\teval's auc: 0.855475\n",
      "[51]\ttrain's auc: 0.91544\teval's auc: 0.856749\n",
      "[52]\ttrain's auc: 0.915318\teval's auc: 0.85972\n",
      "[53]\ttrain's auc: 0.916237\teval's auc: 0.857598\n",
      "[54]\ttrain's auc: 0.916615\teval's auc: 0.858871\n",
      "[55]\ttrain's auc: 0.916993\teval's auc: 0.860569\n",
      "[56]\ttrain's auc: 0.917419\teval's auc: 0.858871\n",
      "[57]\ttrain's auc: 0.917398\teval's auc: 0.85972\n",
      "[58]\ttrain's auc: 0.917169\teval's auc: 0.861418\n",
      "[59]\ttrain's auc: 0.916784\teval's auc: 0.861418\n",
      "[60]\ttrain's auc: 0.916615\teval's auc: 0.860993\n",
      "[61]\ttrain's auc: 0.91725\teval's auc: 0.860144\n",
      "[62]\ttrain's auc: 0.917182\teval's auc: 0.859295\n",
      "[63]\ttrain's auc: 0.916912\teval's auc: 0.85972\n",
      "[64]\ttrain's auc: 0.916453\teval's auc: 0.85972\n",
      "[65]\ttrain's auc: 0.916446\teval's auc: 0.860144\n",
      "[66]\ttrain's auc: 0.916507\teval's auc: 0.860144\n",
      "[67]\ttrain's auc: 0.917067\teval's auc: 0.859295\n",
      "[68]\ttrain's auc: 0.917446\teval's auc: 0.859295\n",
      "[69]\ttrain's auc: 0.917513\teval's auc: 0.858871\n",
      "[70]\ttrain's auc: 0.916845\teval's auc: 0.858447\n",
      "[71]\ttrain's auc: 0.91725\teval's auc: 0.858871\n",
      "[72]\ttrain's auc: 0.917007\teval's auc: 0.859295\n",
      "[73]\ttrain's auc: 0.917101\teval's auc: 0.858871\n",
      "[74]\ttrain's auc: 0.917317\teval's auc: 0.85972\n",
      "[75]\ttrain's auc: 0.917473\teval's auc: 0.860144\n",
      "[76]\ttrain's auc: 0.917358\teval's auc: 0.85972\n",
      "[77]\ttrain's auc: 0.916912\teval's auc: 0.85972\n",
      "[78]\ttrain's auc: 0.917094\teval's auc: 0.859295\n",
      "[79]\ttrain's auc: 0.917385\teval's auc: 0.858871\n",
      "[80]\ttrain's auc: 0.917196\teval's auc: 0.858871\n",
      "[81]\ttrain's auc: 0.917378\teval's auc: 0.858871\n",
      "[82]\ttrain's auc: 0.917338\teval's auc: 0.858447\n",
      "[83]\ttrain's auc: 0.917257\teval's auc: 0.860144\n",
      "[84]\ttrain's auc: 0.916926\teval's auc: 0.860144\n",
      "[85]\ttrain's auc: 0.91675\teval's auc: 0.858871\n",
      "[86]\ttrain's auc: 0.916493\teval's auc: 0.858871\n",
      "[87]\ttrain's auc: 0.916264\teval's auc: 0.860993\n",
      "[88]\ttrain's auc: 0.916176\teval's auc: 0.860993\n",
      "[89]\ttrain's auc: 0.916102\teval's auc: 0.862267\n",
      "[90]\ttrain's auc: 0.916277\teval's auc: 0.862267\n",
      "[91]\ttrain's auc: 0.916547\teval's auc: 0.864389\n",
      "[92]\ttrain's auc: 0.916331\teval's auc: 0.863964\n",
      "[93]\ttrain's auc: 0.916108\teval's auc: 0.865238\n",
      "[94]\ttrain's auc: 0.916297\teval's auc: 0.866087\n",
      "[95]\ttrain's auc: 0.91627\teval's auc: 0.864813\n",
      "[96]\ttrain's auc: 0.916257\teval's auc: 0.864813\n",
      "[97]\ttrain's auc: 0.916264\teval's auc: 0.864813\n",
      "[98]\ttrain's auc: 0.916075\teval's auc: 0.865662\n",
      "[99]\ttrain's auc: 0.916493\teval's auc: 0.866087\n",
      "[100]\ttrain's auc: 0.916385\teval's auc: 0.866935\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(df_train[cat_cols + num_cols], df_train['survived'])\n",
    "lgb_eval = lgb.Dataset(df_val[cat_cols + num_cols], df_val['survived'], reference=lgb_train)\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'auc'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'max_depth': -1,\n",
    "     'boosting_type': 'rf',\n",
    "     'num_leaves': 64,\n",
    "     'colsample_bytree': 0.5,\n",
    "     'n_estimators': 100,\n",
    "     'min_child_weight': 5,\n",
    "     'min_child_samples': 10,\n",
    "     'subsample': 0.632,\n",
    "     'subsample_freq': 1,\n",
    "     'min_split_gain': 0,\n",
    "     'reg_alpha': 0,\n",
    "     'reg_lambda': 0,\n",
    "     'subsample_for_bin': 100,\n",
    "     'n_jobs': -1,\n",
    "    'metric': {'auc'},\n",
    "    'verbose':10\n",
    "}\n",
    "print('Starting training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                valid_sets=[lgb_train,lgb_eval],\n",
    "                valid_names=['train', 'eval'],\n",
    "#                 early_stopping_rounds=0\n",
    "               )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sklearn_novo]",
   "language": "python",
   "name": "conda-env-sklearn_novo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
