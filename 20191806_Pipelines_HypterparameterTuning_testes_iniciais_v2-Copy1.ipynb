{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Definições-iniciais\" data-toc-modified-id=\"Definições-iniciais-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Definições iniciais</a></span><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Configurando-random-pra-deixar-reprodutível\" data-toc-modified-id=\"Configurando-random-pra-deixar-reprodutível-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Configurando random pra deixar reprodutível</a></span></li></ul></li><li><span><a href=\"#Funções-úteis\" data-toc-modified-id=\"Funções-úteis-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Funções úteis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Função-pra-submeter-os-resultados-e-salvar-os-arquivos-necessários-pra-replicar\" data-toc-modified-id=\"Função-pra-submeter-os-resultados-e-salvar-os-arquivos-necessários-pra-replicar-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Função pra submeter os resultados e salvar os arquivos necessários pra replicar</a></span></li><li><span><a href=\"#Custom-transformers\" data-toc-modified-id=\"Custom-transformers-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Custom transformers</a></span></li></ul></li><li><span><a href=\"#Carrega-dados\" data-toc-modified-id=\"Carrega-dados-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Carrega dados</a></span></li><li><span><a href=\"#Criação-de-algumas-features-novas\" data-toc-modified-id=\"Criação-de-algumas-features-novas-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Criação de algumas features novas</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tamanho-de-família\" data-toc-modified-id=\"Tamanho-de-família-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Tamanho de família</a></span></li><li><span><a href=\"#Extrai-o-título\" data-toc-modified-id=\"Extrai-o-título-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Extrai o título</a></span></li><li><span><a href=\"#Acha-aspas-ou-parênteses-no-nome\" data-toc-modified-id=\"Acha-aspas-ou-parênteses-no-nome-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Acha aspas ou parênteses no nome</a></span></li></ul></li><li><span><a href=\"#Definição-do-pipeline-básico-a-ser-otimizado\" data-toc-modified-id=\"Definição-do-pipeline-básico-a-ser-otimizado-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Definição do pipeline básico a ser otimizado</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tratamento-de-categóricas-(transforma-pra-pandas-tipo-categórico-e-garante-mesmas-categorias-no-treino-e-no-teste)\" data-toc-modified-id=\"Tratamento-de-categóricas-(transforma-pra-pandas-tipo-categórico-e-garante-mesmas-categorias-no-treino-e-no-teste)-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Tratamento de categóricas (transforma pra pandas tipo categórico e garante mesmas categorias no treino e no teste)</a></span></li><li><span><a href=\"#Separa-as-amostras-para-treino-e-validação\" data-toc-modified-id=\"Separa-as-amostras-para-treino-e-validação-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Separa as amostras para treino e validação</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T03:51:38.029819Z",
     "start_time": "2019-07-14T03:51:38.026826Z"
    }
   },
   "source": [
    "Vou montar aqui um pipeline mais robusto, mais próximo do produtivo, focando em lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definições iniciais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:33:25.513749Z",
     "start_time": "2019-08-09T01:33:25.500746Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer, TransformedTargetRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, RandomizedSearchCV, train_test_split, StratifiedKFold,cross_val_score\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Pandas numpy etc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# Hyperopt\n",
    "from hyperopt import fmin, hp, tpe, rand, Trials, space_eval, STATUS_OK, anneal\n",
    "from hyperopt.pyll import scope as ho_scope\n",
    "from hyperopt.pyll.stochastic import sample as ho_sample\n",
    "from functools import partial\n",
    "\n",
    "# Category encoders\n",
    "# from category_encoders.hashing import HashingEncoder\n",
    "# from category_encoders.sum_coding import SumEncoder\n",
    "# from category_encoders.woe import WOEEncoder\n",
    "# from category_encoders.target_encoder import TargetEncoder\n",
    "# from category_encoders.one_hot import OneHotEncoder\n",
    "# from category_encoders.binary import BinaryEncoder\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Files\n",
    "# Files e utils\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "from joblib import Memory\n",
    "import joblib\n",
    "import os\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurando random pra deixar reprodutível"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:10:51.561256Z",
     "start_time": "2019-08-09T01:10:51.442148Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "random_global = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções úteis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função pra submeter os resultados e salvar os arquivos necessários pra replicar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:10:51.655690Z",
     "start_time": "2019-08-09T01:10:51.562257Z"
    }
   },
   "outputs": [],
   "source": [
    "class SaveModel(object):\n",
    "    def __init__(self, folder_to_save, data_train=None, data_val=None, data_test=None, model=None, str_readme=None, submission_file='submission.csv'):\n",
    "        self.folder_to_save = folder_to_save\n",
    "        self.data_train = data_train\n",
    "        self.data_val = data_val\n",
    "        self.data_test = data_test\n",
    "        self.model = model\n",
    "        self.str_readme = str_readme\n",
    "        self.submission_file = submission_file\n",
    "    \n",
    "    def save_model(self):\n",
    "#     Create folder if not exists:\n",
    "        try:\n",
    "            os.makedirs(self.folder_to_save)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    #     Salva os dados usados no treino\n",
    "        if self.data_train is not None:\n",
    "            joblib.dump(self.data_train, self.folder_to_save+'/train_data')\n",
    "\n",
    "\n",
    "    #     Salva dados usados na validação\n",
    "        if self.data_val is not None:\n",
    "            joblib.dump(self.data_test, self.folder_to_save+'/validation_data')\n",
    "\n",
    "    #     Salva dados usados no teste\n",
    "        if self.data_test is not None:\n",
    "            joblib.dump(self.data_test, self.folder_to_save+'/test_data')\n",
    "\n",
    "    #     Salva modelo \n",
    "        if self.model is not None:\n",
    "            joblib.dump(self.model, self.folder_to_save+'/model')   \n",
    "\n",
    "    #     Arquivo README (é o que vai escrito pro commit)\n",
    "        with open(self.folder_to_save+'/README.txt', \"w\") as text_file:\n",
    "            text_file.write(self.str_readme)\n",
    "            \n",
    "#         Salva os predictions\n",
    "        \n",
    "\n",
    "    def commit_kaggle(self):\n",
    "        predictions = self.model.predict(self.data_test)\n",
    "        submission = pd.DataFrame({'PassengerId':self.data_test['passengerid'],'Survived':predictions})\n",
    "        submission.to_csv(self.folder_to_save+'/'+self.submission_file,index=False)\n",
    "#         print(f\"kaggle competitions submit -c titanic -f submission.csv -m \\\"{self.str_readme}\\\"\")\n",
    "#         !! f\"kaggle competitions submit -c titanic -f {self.folder_to_save+'/'+self.submission_file} -m \\\"{self.str_readme}\\\"\"\n",
    "        if os.system(f\"kaggle competitions submit -c titanic -f {self.folder_to_save+'/'+self.submission_file} -m \\\"{self.str_readme}\\\"\") != 0:\n",
    "            print('Erro submetendo o arquivo no kaggle!')\n",
    "            \n",
    "        print(f\"kaggle competitions submit -c titanic -f {self.folder_to_save+'/'+self.submission_file} -m \\\"{self.str_readme}\\\"\")\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:10:51.780244Z",
     "start_time": "2019-08-09T01:10:51.656691Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from functools import reduce\n",
    "\n",
    "class TransformToDF(BaseEstimator, TransformerMixin):\n",
    "    '''Wrapper para usar transformers do sklearn mas retorna um dataframe Pandas. Projetei para usar com transformers que não\n",
    "    mudam o número de colunas na saída.'''\n",
    "    \n",
    "    def __init__(self, sklearn_transformer, return_df=True):\n",
    "        self.sklearn_transformer = sklearn_transformer\n",
    "        self.return_df = return_df\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            self.col_names = X.columns.values.tolist()\n",
    "            \n",
    "        self.sklearn_transformer.fit(X, y=None)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "    # assumes X is a DataFrame\n",
    "        if self.return_df:\n",
    "            return pd.DataFrame(self.sklearn_transformer.transform(X[self.col_names]), index=X.index, columns=self.col_names)\n",
    "        else:\n",
    "            return self.sklearn_transformer.transform(X)\n",
    "        \n",
    "class DFFeatureUnion(BaseEstimator,TransformerMixin):\n",
    "    # FeatureUnion but for pandas DataFrames\n",
    "\n",
    "    def __init__(self, transformer_list):\n",
    "        self.transformer_list = transformer_list\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for (name, t) in self.transformer_list:\n",
    "            t.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xts = [t.transform(X) for _, t in self.transformer_list]\n",
    "        Xunion = reduce(lambda X1, X2: pd.merge(X1, X2, left_index=True, right_index=True), Xts)\n",
    "        return Xunion\n",
    "    \n",
    "class ColumnExtractor(BaseEstimator,TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols, return_df=True):\n",
    "        self.cols = cols\n",
    "        self.return_df = return_df\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # stateless transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        if self.return_df:\n",
    "            return X[self.cols]\n",
    "        else:\n",
    "            return X[self.cols].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carrega dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:10:51.927880Z",
     "start_time": "2019-08-09T01:10:51.781228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print shape df_train_val: (891, 12)\n",
      "Print shape df_test: (418, 11)\n"
     ]
    }
   ],
   "source": [
    "df_train_val = pd.read_csv(\"./data/train.csv\")\n",
    "df_test = pd.read_csv(\"./data/test.csv\")\n",
    "df_train_val.columns = [x.lower() for x in df_train_val.columns]\n",
    "df_test.columns = [x.lower() for x in df_test.columns]\n",
    "\n",
    "print(f'Print shape df_train_val: {df_train_val.shape}')\n",
    "print(f'Print shape df_test: {df_test.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação de algumas features novas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tamanho de família"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:10:52.035264Z",
     "start_time": "2019-08-09T01:10:51.928882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family_size</th>\n",
       "      <th>size</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>537</td>\n",
       "      <td>0.303538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>161</td>\n",
       "      <td>0.552795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>0.578431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>0.724138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   family_size  size      mean\n",
       "0            1   537  0.303538\n",
       "1            2   161  0.552795\n",
       "2            3   102  0.578431\n",
       "3            4    29  0.724138\n",
       "4            5    15  0.200000\n",
       "5            6    22  0.136364\n",
       "6            7    12  0.333333\n",
       "7            8     6  0.000000\n",
       "8           11     7  0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "family_size\n",
       "1     253\n",
       "2      74\n",
       "3      57\n",
       "4      14\n",
       "5       7\n",
       "6       3\n",
       "7       4\n",
       "8       2\n",
       "11      4\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_data = [df_train_val, df_test]\n",
    "for dataset in full_data:\n",
    "    dataset['family_size'] = 1 + dataset['parch'] + dataset['sibsp']\n",
    "    if 'survived' in dataset.columns:\n",
    "        display(dataset.fillna(-999).groupby('family_size')['survived'].agg(['size', 'mean']).reset_index())\n",
    "    else:\n",
    "        display(dataset.fillna(-999).groupby('family_size').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aparentemente depois de 4 familiares, talvez seja bom juntar depois"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrai o título"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:10:52.235689Z",
     "start_time": "2019-08-09T01:10:52.036255Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>size</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sir</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Countess</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ms</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mme</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lady</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mlle</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mrs</td>\n",
       "      <td>125</td>\n",
       "      <td>0.792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Miss</td>\n",
       "      <td>182</td>\n",
       "      <td>0.697802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Master</td>\n",
       "      <td>40</td>\n",
       "      <td>0.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Col</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Major</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dr</td>\n",
       "      <td>7</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mr</td>\n",
       "      <td>517</td>\n",
       "      <td>0.156673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jonkheer</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Don</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Rev</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Capt</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title  size      mean\n",
       "16       Sir     1  1.000000\n",
       "2   Countess     1  1.000000\n",
       "14        Ms     1  1.000000\n",
       "11       Mme     1  1.000000\n",
       "6       Lady     1  1.000000\n",
       "10      Mlle     2  1.000000\n",
       "13       Mrs   125  0.792000\n",
       "9       Miss   182  0.697802\n",
       "8     Master    40  0.575000\n",
       "1        Col     2  0.500000\n",
       "7      Major     2  0.500000\n",
       "4         Dr     7  0.428571\n",
       "12        Mr   517  0.156673\n",
       "5   Jonkheer     1  0.000000\n",
       "3        Don     1  0.000000\n",
       "15       Rev     6  0.000000\n",
       "0       Capt     1  0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "title\n",
       "Col         2\n",
       "Dona        1\n",
       "Dr          1\n",
       "Master     21\n",
       "Miss       78\n",
       "Mr        240\n",
       "Mrs        72\n",
       "Ms          1\n",
       "Rev         2\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_data = [df_train_val, df_test]\n",
    "for dataset in full_data:\n",
    "    dataset['title'] = dataset['name'].str.findall('([A-Z][a-z]+)\\.').map(lambda x: x[0])\n",
    "    if 'survived' in dataset.columns:\n",
    "        display(dataset.fillna(-999).groupby('title')['survived'].agg(['size', 'mean']).reset_index().sort_values(by='mean', ascending=False))\n",
    "    else:\n",
    "        display(dataset.fillna(-999).groupby('title').size())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T02:19:52.456496Z",
     "start_time": "2019-07-09T02:19:52.417461Z"
    }
   },
   "source": [
    "## Acha aspas ou parênteses no nome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:10:58.072909Z",
     "start_time": "2019-08-09T01:10:58.033873Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_aspas</th>\n",
       "      <th>size</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.716981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>838</td>\n",
       "      <td>0.362768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name_aspas  size      mean\n",
       "1           1    53  0.716981\n",
       "0           0   838  0.362768"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_parenteses</th>\n",
       "      <th>size</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>748</td>\n",
       "      <td>0.310160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name_parenteses  size      mean\n",
       "1                1   143  0.769231\n",
       "0                0   748  0.310160"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "name_aspas\n",
       "0    396\n",
       "1     22\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "name_parenteses\n",
       "0    340\n",
       "1     78\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_data = [df_train_val, df_test]\n",
    "for dataset in full_data:\n",
    "    dataset['name_aspas'] = dataset['name'].str.findall('\\\"').map(lambda x: len(x) >= 1 ).astype('int')\n",
    "    dataset['name_parenteses'] = dataset['name'].str.findall('\\(').map(lambda x: len(x) >= 1 ).astype('int')\n",
    "    if 'survived' in dataset.columns:\n",
    "        display(dataset.fillna(-999).groupby('name_aspas')['survived'].agg(['size', 'mean']).reset_index().sort_values(by='mean', ascending=False))\n",
    "        display(dataset.fillna(-999).groupby('name_parenteses')['survived'].agg(['size', 'mean']).reset_index().sort_values(by='mean', ascending=False))\n",
    "    else:\n",
    "        display(dataset.fillna(-999).groupby('name_aspas').size())\n",
    "        display(dataset.fillna(-999).groupby('name_parenteses').size())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definição do pipeline básico a ser otimizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento de categóricas (transforma pra pandas tipo categórico e garante mesmas categorias no treino e no teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:11:00.004945Z",
     "start_time": "2019-08-09T01:11:00.001943Z"
    }
   },
   "outputs": [],
   "source": [
    "num_cols = ['age', 'sibsp', 'parch', 'fare', 'family_size']\n",
    "cat_cols = ['sex', 'embarked', 'title', 'name_aspas', 'name_parenteses', 'pclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:11:00.700918Z",
     "start_time": "2019-08-09T01:11:00.690918Z"
    }
   },
   "outputs": [],
   "source": [
    "dict_dtypes = {}\n",
    "for col in cat_cols + num_cols:\n",
    "    if col in cat_cols:\n",
    "        dict_dtypes[col] = CategoricalDtype(categories=df_train_val[col].dropna().unique(), ordered=False)\n",
    "    else:\n",
    "        dict_dtypes[col] = df_train_val[col].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:11:03.886652Z",
     "start_time": "2019-08-09T01:11:03.876634Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_val = df_train_val.astype(dict_dtypes)\n",
    "df_test = df_test.astype(dict_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:19:15.286941Z",
     "start_time": "2019-08-09T01:19:15.266925Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>embarked</th>\n",
       "      <th>title</th>\n",
       "      <th>name_aspas</th>\n",
       "      <th>name_parenteses</th>\n",
       "      <th>pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sex  embarked  title  name_aspas  name_parenteses  pclass\n",
       "0      0         0      0           0                0       0\n",
       "1      1         1      1           0                1       1\n",
       "2      1         0      2           0                0       0\n",
       "3      1         0      1           0                1       1\n",
       "4      0         0      0           0                0       0\n",
       "5      0         2      0           0                0       0\n",
       "6      0         0      0           0                0       1\n",
       "7      0         0      3           0                0       0\n",
       "8      1         0      1           0                1       0\n",
       "9      1         1      1           0                1       2\n",
       "10     1         0      2           0                0       0\n",
       "11     1         0      2           0                0       1\n",
       "12     0         0      0           0                0       0\n",
       "13     0         0      0           0                0       0\n",
       "14     1         0      2           0                0       0\n",
       "15     1         0      1           0                1       2\n",
       "16     0         2      3           0                0       0\n",
       "17     0         0      0           0                0       2\n",
       "18     1         0      1           0                1       0\n",
       "19     1         1      1           0                0       0\n",
       "20     0         0      0           0                0       2\n",
       "21     0         0      0           0                0       2\n",
       "22     1         2      2           1                0       0\n",
       "23     0         0      0           0                0       1\n",
       "24     1         0      2           0                0       0\n",
       "25     1         0      1           0                1       0\n",
       "26     0         1      0           0                0       0\n",
       "27     0         0      0           0                0       1\n",
       "28     1         2      2           1                0       0\n",
       "29     0         0      0           0                0       0\n",
       "..   ...       ...    ...         ...              ...     ...\n",
       "861    0         0      0           0                0       2\n",
       "862    1         0      1           0                1       1\n",
       "863    1         0      2           1                0       0\n",
       "864    0         0      0           0                0       2\n",
       "865    1         0      1           0                1       2\n",
       "866    1         1      2           0                0       2\n",
       "867    0         0      0           0                0       1\n",
       "868    0         0      0           0                0       0\n",
       "869    0         0      3           0                0       0\n",
       "870    0         0      0           0                0       0\n",
       "871    1         0      1           0                1       1\n",
       "872    0         0      0           0                0       1\n",
       "873    0         0      0           0                0       0\n",
       "874    1         1      1           0                1       2\n",
       "875    1         1      2           1                0       0\n",
       "876    0         0      0           0                0       0\n",
       "877    0         0      0           0                0       0\n",
       "878    0         0      0           0                0       0\n",
       "879    1         1      1           0                1       1\n",
       "880    1         0      1           0                1       2\n",
       "881    0         0      0           0                0       0\n",
       "882    1         0      2           0                0       0\n",
       "883    0         0      0           0                0       2\n",
       "884    0         0      0           0                0       0\n",
       "885    1         2      1           0                1       0\n",
       "886    0         0      5           0                0       2\n",
       "887    1         0      2           0                0       1\n",
       "888    1         0      2           1                0       0\n",
       "889    0         1      0           0                0       1\n",
       "890    0         2      0           0                0       0\n",
       "\n",
       "[891 rows x 6 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_val[cat_cols].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separa as amostras para treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df_train_val, test_size = 100, shuffle=True, stratify=df_train_val['survived'], random_state=random_global)\n",
    "print(f'Print shape df_train: {df_train.shape}')\n",
    "print(f'Print shape df_val: {df_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:12:21.526105Z",
     "start_time": "2019-08-09T01:12:21.522111Z"
    }
   },
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:46:59.641281Z",
     "start_time": "2019-08-09T01:46:59.637287Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cat_codes(X):\n",
    "    return X.apply(lambda x: x.cat.codes).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:49:13.039999Z",
     "start_time": "2019-08-09T01:49:13.028990Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 1., 0.],\n",
       "       [0., 1., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 1., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 1., 0.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_pipeline(FunctionTransformer(get_cat_codes, validate=False), OneHotEncoder(categories='auto', sparse=False)).fit_transform(df_train_val[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_pipeline(SimpleImputer(fill_value=0, strategy=hps['num_missing_strategy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:48:34.441465Z",
     "start_time": "2019-08-09T01:48:34.429454Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>embarked</th>\n",
       "      <th>title</th>\n",
       "      <th>name_aspas</th>\n",
       "      <th>name_parenteses</th>\n",
       "      <th>pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex embarked title name_aspas name_parenteses pclass\n",
       "0    male        S    Mr          0               0      3\n",
       "1  female        C   Mrs          0               1      1\n",
       "2  female        S  Miss          0               0      3\n",
       "3  female        S   Mrs          0               1      1\n",
       "4    male        S    Mr          0               0      3"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_val[cat_cols+num_cols].iloc[:, :-len(num_cols)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T02:24:28.674650Z",
     "start_time": "2019-08-09T02:24:28.623603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'class_weight': None,\n",
       " 'colsample_bytree': 1.0,\n",
       " 'importance_type': 'split',\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': -1,\n",
       " 'min_child_samples': 20,\n",
       " 'min_child_weight': 0.001,\n",
       " 'min_split_gain': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': -1,\n",
       " 'num_leaves': 31,\n",
       " 'objective': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': 0.0,\n",
       " 'reg_lambda': 0.0,\n",
       " 'silent': True,\n",
       " 'subsample': 1.0,\n",
       " 'subsample_for_bin': 200000,\n",
       " 'subsample_freq': 0}"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGBMClassifier().fit().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T02:26:44.705136Z",
     "start_time": "2019-08-09T02:26:44.699141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex                category\n",
       "embarked           category\n",
       "title              category\n",
       "name_aspas         category\n",
       "name_parenteses    category\n",
       "pclass             category\n",
       "dtype: object"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_val[cat_cols].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T03:00:52.112015Z",
     "start_time": "2019-08-09T03:00:52.106009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 6)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cat_codes(df_train_val[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature=10\n",
    "get_cat_codes(df_train_val[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T03:01:23.594241Z",
     "start_time": "2019-08-09T03:01:23.435106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score médio nas partições de treino : 0.8813839380376425\n",
      "score médio nas partições de validação : 0.8591366579993132\n"
     ]
    }
   ],
   "source": [
    "a = LGBMClassifier(min_data_per_group=50)\n",
    "crossval = cross_validate(a, get_cat_codes(df_train_val[cat_cols]), df_train_val['survived'], return_train_score=True, cv=kf, scoring='roc_auc')\n",
    "# .fit(df_train_val[cat_cols], df_train_val['survived'])\n",
    "print(f\"score médio nas partições de treino : {crossval['train_score'].mean()}\")\n",
    "print(f\"score médio nas partições de validação : {crossval['test_score'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T03:01:12.914123Z",
     "start_time": "2019-08-09T03:01:12.617854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score médio nas partições de treino : 0.8819628981552233\n",
      "score médio nas partições de validação : 0.859277038552303\n"
     ]
    }
   ],
   "source": [
    "a = LGBMClassifier(min_data_per_group=50)\n",
    "crossval = cross_validate(a, df_train_val[cat_cols], df_train_val['survived'], return_train_score=True, cv=kf, scoring='roc_auc')\n",
    "# .fit(df_train_val[cat_cols], df_train_val['survived'])\n",
    "print(f\"score médio nas partições de treino : {crossval['train_score'].mean()}\")\n",
    "print(f\"score médio nas partições de validação : {crossval['test_score'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = LGBMClassifier(**{'min_data_per_group':1})\n",
    "crossval = cross_validate(a, df_train_val[num_cols], df_train_val['survived'], return_train_score=True, cv=kf, scoring='roc_auc')\n",
    "# .fit(df_train_val[cat_cols], df_train_val['survived'])\n",
    "print(f\"score médio nas partições de treino : {crossval['train_score'].mean()}\")\n",
    "print(f\"score médio nas partições de validação : {crossval['test_score'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_clf(hps):\n",
    "    \"\"\"\n",
    "    Constructs estimator\n",
    "    \n",
    "    Parameters:\n",
    "    ----------------\n",
    "    hps : sample point from search space\n",
    "    \n",
    "    Returns:\n",
    "    ----------------\n",
    "    model : sklearn.Pipeline.pipeline with hyperparameters set up as per hps\n",
    "    \"\"\"\n",
    "    if hps['categ_encoder'] == 'one_hot'\n",
    "    \n",
    "    cat_pipeline = make_pipeline(FunctionTransformer(get_cat_codes, validate=False), OneHotEncoder(categories='auto', sparse=False))\n",
    "    num_pipeline = make_pipeline(ColumnExtractor(num_cols, return_df=True), TransformToDF(SimpleImputer(fill_value=0, strategy=hps['num_missing_strategy'])\n",
    "                                                                          , return_df=True),TransformToDF(StandardScaler()))\n",
    "    \n",
    "    if hps['clf_type']['type'] == 'logit':\n",
    "        clf = LogisticRegression(**hps['clf_type']['clf'], solver='sag', max_iter=25000, random_state=random_global)\n",
    "    elif hps['clf_type']['type'] == 'SVM':\n",
    "        clf = SVC(**f_unpack_dict(hps['clf_type']['clf']), probability=True, random_state=random_global)\n",
    "    elif hps['clf_type']['type'] == 'RandomForest':\n",
    "        clf = RandomForestClassifier(**f_unpack_dict(hps['clf_type']['clf']), random_state=random_global)\n",
    "    else:\n",
    "        raise KeyError('Unknown classifier type hyperparameter value: {0}'.format(hps['clf_type']['type']))\n",
    "    \n",
    "    model = Pipeline([('features', DFFeatureUnion([('cat_flow',cat_pipeline), ('num_flow',num_pipeline)])), ('clf', clf)])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:29:26.133642Z",
     "start_time": "2019-08-09T01:29:26.116627Z"
    }
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "hp_space_lgb ={\n",
    "    'num_missing_strategy': hp.choice('num_missing_strategy', ['mean', 'median', 'constant']),\n",
    "#     'categ_encoder': hp.choice('categ_encoder', ['woe','one_hot','target_encoder', 'lgbm_internal']),\n",
    "    'categ_encoder': hp.choice('categ_encoder', ['one_hot','label_encoder', 'lgbm_internal']),\n",
    "        # type refers to classifier type: either logit or SVM\n",
    "    'clf_type': hp.choice('clf_type', [\n",
    "        {\n",
    "            'type': 'logit',\n",
    "            'clf': {\n",
    "                'C': hp.loguniform('logit.C', -4.0*np.log(10.0), 4.0*np.log(10.0)), \n",
    "                'class_weight': hp.choice('logit.class_weight', [None, 'balanced'])\n",
    "            }\n",
    "        }, \n",
    "        {\n",
    "            'type': 'SVM', \n",
    "            'clf': {\n",
    "                'C': hp.loguniform('svm.C', -4.0*np.log(10.0), 4.0*np.log(10.0)), \n",
    "                'class_weight': hp.choice('svm.class_weight', [None, 'balanced']), \n",
    "                'kernel': 'rbf', \n",
    "                'gamma': hp.choice('svm.gamma', ['auto', 'scale'])\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'type': 'lgbm_rf',\n",
    "            'clf': {\n",
    "                'max_depth': 5,\n",
    "                'boosting_type': \"rf\",\n",
    "                'num_leaves': 165,\n",
    "                'colsample_bytree': .5,\n",
    "                'n_estimators': 2000,\n",
    "                'min_child_weight': 5,\n",
    "                'min_child_samples': 10,\n",
    "                'subsample': .632, # Standard RF bagging fraction\n",
    "                'subsample_freq': 1,\n",
    "                'min_split_gain': 0,\n",
    "                'reg_alpha': 0, \n",
    "                'reg_lambda': 0,\n",
    "                'subsample_for_bin':200000,\n",
    "                'min_data_per_group': 5\n",
    "                \n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'type': 'RandomForest', \n",
    "            'clf': {\n",
    "                    'bootstrap': hp.choice('rf.bootstrap', [False, True]),\n",
    "                    'class_weight': hp.choice('rf.class_weight',['balanced', 'balanced_subsample', None]),\n",
    "                    'criterion': hp.choice('rf.criterion', ['gini', 'entropy']),\n",
    "                    'max_depth': ho_scope.int(hp.uniform('rf.max_depth', low=1, high=11)),\n",
    "                    'max_features': hp.choice('rf.max_features', ['auto','sqrt', None]),\n",
    "                    'max_leaf_nodes': ho_scope.int(hp.uniform('rf.max_leaf_nodes', low=2, high=1024)),\n",
    "                    'min_samples_split': ho_scope.int(hp.uniform('rf.min_samples_split', low=2, high=1024)),\n",
    "                    'min_weight_fraction_leaf': 0.1 * ho_scope.int(hp.uniform('rf.min_weight_fraction_leaf', low=0, high=5)),\n",
    "                    'n_estimators': 100 * ho_scope.int(hp.uniform('rf.n_estimators', low=1, high=10)),\n",
    "                    'oob_score': False\n",
    "            }\n",
    "        }\n",
    "    ])\n",
    "}\n",
    "\n",
    "\n",
    "def f_wrap_space_eval(hp_space, trial):\n",
    "    \"\"\"\n",
    "    Utility function for more consise optimization history extraction\n",
    "    \n",
    "    Parameters:\n",
    "    ----------------\n",
    "    hp_space : hyperspace from which points are sampled\n",
    "    trial : hyperopt.Trials object\n",
    "    \n",
    "    Returns:\n",
    "    ----------------\n",
    "    : dict(\n",
    "        k: v\n",
    "    ), where k - label of hyperparameter, v - value of hyperparameter in trial\n",
    "    \"\"\"\n",
    "    \n",
    "    return space_eval(hp_space, {k: v[0] for (k, v) in trial['misc']['vals'].items() if len(v) > 0})\n",
    "\n",
    "\n",
    "def f_unpack_dict(dct):\n",
    "    \"\"\"\n",
    "    Unpacks all sub-dictionaries in given dictionary recursively. There should be no duplicated keys \n",
    "    across all nested subdictionaries, or some instances will be lost without warning\n",
    "    \n",
    "    Parameters:\n",
    "    ----------------\n",
    "    dct : dictionary to unpack\n",
    "    \n",
    "    Returns:\n",
    "    ----------------\n",
    "    : unpacked dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    res = {}\n",
    "    for (k, v) in dct.items():\n",
    "        if isinstance(v, dict):\n",
    "            res = {**res, **f_unpack_dict(v)}\n",
    "        else:\n",
    "            res[k] = v\n",
    "            \n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score médio nas partições de treino : 0.8949813024613473\n",
    "score médio nas partições de validação : 0.8673248129740319\n",
    "AUC treino: 0.896919\n",
    "AUC validação: 0.846986"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T04:39:32.127117Z",
     "start_time": "2019-08-08T04:39:27.516919Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cross validation no treino\n",
    "clf = LGBMClassifier(**params_rf)\n",
    "crossval = cross_validate(clf, df_train.astype({x: 'category' for x in cat_cols})[cat_cols+num_cols]\\\n",
    "                          , df_train['survived'], return_train_score=True, cv=kf, scoring='roc_auc')\n",
    "\n",
    "print(f\"score médio nas partições de treino : {crossval['train_score'].mean()}\")\n",
    "print(f\"score médio nas partições de validação : {crossval['test_score'].mean()}\")\n",
    "      \n",
    "clf.fit(df_train.astype({x: 'category' for x in cat_cols})[cat_cols+num_cols], df_train['survived'])\n",
    "\n",
    "print('AUC treino: %f' % roc_auc_score(df_train['survived'], clf.predict_proba(df_train.astype({x: 'category' for x in cat_cols})[cat_cols+num_cols])[:,1]))\n",
    "print('AUC validação: %f' % roc_auc_score(df_val['survived'], clf.predict_proba(df_val.astype({x: 'category' for x in cat_cols})[cat_cols+num_cols])[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:22:38.378930Z",
     "start_time": "2019-08-09T01:22:38.376927Z"
    }
   },
   "outputs": [],
   "source": [
    "from lightgbm import plot_importance, plot_metric, plot_tree, plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:22:38.692527Z",
     "start_time": "2019-08-09T01:22:38.682518Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-1d0b3a40c682>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_importance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimportance_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gain'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_zero\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "plot_importance(clf, importance_type='gain', ignore_zero=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:22:45.790699Z",
     "start_time": "2019-08-09T01:22:45.786687Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, bagging, BaseEnsemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T01:22:47.476692Z",
     "start_time": "2019-08-09T01:22:47.458676Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-d54a890a0cee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Cross validation no treino\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbagging_lgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m crossval = cross_validate(clf, df_train.astype({x: 'category' for x in cat_cols})[cat_cols+num_cols]\\\n\u001b[0m\u001b[0;32m     21\u001b[0m                           , df_train['survived'], return_train_score=True, cv=kf, scoring='roc_auc')\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "lgbm_single_tree = {\n",
    "    'max_depth': 20,\n",
    "    'boosting_type': \"rf\",\n",
    "    'num_leaves': 165,\n",
    "    'colsample_bytree': 1,\n",
    "    'n_estimators': 1,\n",
    "    'min_child_weight': 0,\n",
    "    'min_child_samples': 0,\n",
    "    'subsample': .99999, # Standard RF bagging fraction\n",
    "    'subsample_freq': 1,\n",
    "    'min_split_gain': 0,\n",
    "    'reg_alpha': 0, # Hard L1 regularization\n",
    "    'reg_lambda': 0,\n",
    "    'subsample_for_bin':200000,\n",
    "    'n_jobs': 1}\n",
    "\n",
    "bagging_lgb = BaggingClassifier(base_estimator=LGBMClassifier(**lgbm_single_tree), n_estimators=1000, bootstrap=True)\n",
    "# Cross validation no treino\n",
    "clf = bagging_lgb\n",
    "crossval = cross_validate(clf, df_train.astype({x: 'category' for x in cat_cols})[cat_cols+num_cols]\\\n",
    "                          , df_train['survived'], return_train_score=True, cv=kf, scoring='roc_auc')\n",
    "\n",
    "print(f\"score médio nas partições de treino : {crossval['train_score'].mean()}\")\n",
    "print(f\"score médio nas partições de validação : {crossval['test_score'].mean()}\")\n",
    "      \n",
    "clf.fit(df_train.astype({x: 'category' for x in cat_cols})[cat_cols+num_cols], df_train['survived'])\n",
    "\n",
    "print('AUC treino: %f' % roc_auc_score(df_train['survived'], clf.predict_proba(df_train.astype({x: 'category' for x in cat_cols})[cat_cols+num_cols])[:,1]))\n",
    "print('AUC validação: %f' % roc_auc_score(df_val['survived'], clf.predict_proba(df_val.astype({x: 'category' for x in cat_cols})[cat_cols+num_cols])[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sklearn_novo]",
   "language": "python",
   "name": "conda-env-sklearn_novo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
